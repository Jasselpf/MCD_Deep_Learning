---
title: "DL_20200206"
author: "Soledad Perez"
date: "February 6, 2020"
output: html_document
---



## Deep Learning - clase febrero 2, 2020


### Optimizadores

#### Gradient Descent (GD)

Descenso en gradiente es un algoritmo de optimización usado para minimizar alguna función al moverse itarativamente 
en la direción de mayor descenso (steppest descent) definido por el negativo del gradiente. 

$$\Omega = \Omega - \eta \nabla J(\Omega)$$
$$\omega_i = \omega_i - \eta \frac{\partial E}{\partial \omega_i}$$

$\eta:$ taza de aprendizaje

#### Stochastic Gradient Descent



### Preguntas posibles para el exámen

1. ¿Qué es deep learning? 

Deep Learning es una técnica o sub área de aprendizaje automático (machine leanring) basada en aprender características
y tareas directamente de los datos. Se caracteriza por estar compuesto por redes neuronales para el 
procesaminento de la información.


2. ¿Qué lo hace deep learning? 

La principal distinción del deep learning se establece por su estructura y procesamiento de la información el cual imita las 
redes neuronales del cerebro humano. El término deep hace referencia a las capas ocultas de estas redes, que generalmente 
son del orden de decenas a centenas.


3. Relación entre regresión y clasificación. ¿Por qué son modelos equivalentes? 

En un modelo de regresión los valores que se desan reproducir tiene valores continuos, mientras que en los problemas de clasificación 
los valores de los conjuntos que se desean reproducir son categorías. Su similitud es que en un modelo de regresión los resultados 
se pueden discretizar para obtener las categorías necesarias en base a una probabilidad.


4. Conjuntos de datos Test y Prueba. 

El conjunto entrenamiento se utiliza para ajustar los parámetros del modelo.
El conjunto de validación se utiliza para ajustar los hiperparámetros del modelo.
El conjunto de prueba se utiliza para evaluar el desempeño del modelo.


5. Diferencia entre parámetro o hiperparámetro

Parámetros: son los que el modelo aprende por si solo, por ejemplo los pesos o biases.

Hiperparámetros: son utilizados para optimizar el desempeño del modelo, por ejemplo el número de capas ocultas, tasa de aprendizaje, etc. 


6. Perceptrón. Idea, ¿qué modela?, ¿cómo calculo el número de parámetros? y ¿qué debo considerar?


Perceptrón es un clasificador linear binario y consiste de cuatro partes: input values, pesos y bias, suma total (S), 
y una función de activación. La función de activación es utilizada para obtener un resultado acotado, generalmente entre (0,1), o
(-1,1)


7. Backprop, si tengo una red de este tipo, ¿qué parametros debo de considerar?

Si mi problema es no lineal entonces es conveniente usar una red neuronal. Si mi problema es altamente lineal, entonces es mejor
resolverlo de la manera tradicional.

El objetivo de backpropagation es ajustar cada peso en la red en proporción a su contribución al error. Si reducimos iterativamente
el error de cada peso, eventualmente obtendremos los pesos adecuados para obtener buenas predicciones.


8. Vanishing gradient / Exploding gradient problem

Si la función de activacion tiene una derivada que pueda tomar valores muy grandes, uno de los riesgos que se presentan es 
el llamado exploding gradient problem.

El término vanishing problem se refiere cuando en un red neuronal no es capaz de propagar información útil del gradiente desde 
la salida/output final del modelo hasta las capas cercanas al input del modelo. Esto se observa cuando en un modelo con muchas 
capas es incapaz de aprender con el modelo de datos, o cuando se alcanza una convergencia premarura a una solución probre.
La solución más usada en estos casos es utilizar estas funciones de activación: ReLu, Leaky ReLu, o Elu (exponencial
linar unit)


9. Funciones de activación, ¿cuándo es recomendable usar una u otra?

* Lineal - Da un rango de activaciones, no es una activación no lineal

* Step

* Sigmoide - se utiliza generalmente con clasificasión binaria

* ReLu - Usar en capas intermedias

* Leaky ReLu - Usado principalmente cuando tenemos neuronas muertas o de lado negativo

* Elu (exponencial linar unit)

* Sof Plus

* Max Out 

* SoftMax - Usar softmax en la capa de salida si es clasificación multiclase


10. Funciones de pérdida, ¿cuándo conviene usar una u otra?

* MSE (mean square error) - aka L2 loss - se usa para regresión

* MAE (mean absolute arror) - aka L1 loss - se usa para regresión

* Huber Loss - combinación entre pérdidas L2 y L1 - se usa para regresión

* Categorical cross entropy - se usa en clasificación

* Binary cross entropy - se usa en clasificación binaria

* Dibergencia Kullbak Leibler (D_KL)



11. Optimizadores

* Gradient Descent - (GD) - base de todos los optimizadores

* Stochastic Gradiente Descent (SGD) - es útil para escapar de mínimos locales

* Minibatch Gradient Descent - es lo que se utiliza en la práctica. \
  Usa lotes \
  Actualiza parámetros por lote \
  Los lotes generalmente deben de ser mayores de 32 y menores de 256 \
  
* Momentum - acelera la bajada y disminuye oscilaciones \
  Por la acumulación de gradientes, los pesos van a converger hacia un error apropiado 
  mucho más rápido \
  Es comparable con el momento en física

* Nesterov Accelerated Gradient (NAG) - anticipa cambios de dirección. \
  En lugar de calcular el gradiente en la posición actual, se trata de calcular
  en una posición futura aproximada
  Funciona bien para redes recurrentes \
  Evalua el costo de moverme \ 
  
* Ada Gradient (Adagrad) - modelos adaptativos \
  El learning rate y el coeficiente de momento no permanecen constantes, estos valores se van adaptando 
  para cada peso en la red \
  Eta bajo para variables frecuentes, con pocos pasos se aprende lo necesario \
  Eta alto para variables poco frecuentes \
  Funciona bien con datos ralos \
  La desventaje con este modelo es que sin importar los gradientes de los pesos pasados
  el cache para la actualziación siempre va a incrementar ya que el cuadrado del gradiente siempre 
  es positivo, lo que resultará es que el entrenamiento va a dejar de ser significante
  
* Adadelta \
  Trata de resolver el problema del incremento monótono en el denominador de Adagrad \
  Restringe la historia a una ventana temporal
  
* RMSprop \
  La caida del error no es tan rápida \
  Similar que Adadelta pero con una tasa de decaimiento (-.9) y momento dadas (0.001) \ 
  
* Adam - es el más usado excepto cuando tienes datos ralos \
  Se puede pensar como una combinación entre Adadelta y Momentum


  
  
  
  









